{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def download_file(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "def extract_zip(zip_file, destination):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    (\"https://zenodo.org/record/1186215/files/adelaide.zip?download=1\", \"adelaide.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/belfast.zip?download=1\", \"belfast.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/berlin.zip?download=1\", \"berlin.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/bordeaux.zip?download=1\", \"bordeaux.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/brisbane.zip?download=1\",\"brisbane.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/canberra.zip?download=1\",\"canberra.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/detroit.zip?download=1\",\"detroit.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/dublin.zip?download=1\",\"dublin.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/grenoble.zip?download=1\",\"grenoble.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/helsinki.zip?download=1\",\"helsinki.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/kuopio.zip?download=1\",\"kuopio.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/lisbon.zip?download=1\",\"lisbon.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/luxembourg.zip?download=1\",\"luxembourg.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/melbourne.zip?download=1\",\"melbourne.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/nantes.zip?download=1\",\"nantes.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/palermo.zip?download=1\",\"palermo.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/paris.zip?download=1\",\"paris.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/prague.zip?download=1\",\"prague.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/rennes.zip?download=1\",\"rennes.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/rome.zip?download=1\",\"rome.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/sydney.zip?download=1\",\"sydney.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/toulouse.zip?download=1\",\"toulouse.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/turku.zip?download=1\",\"turku.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/venice.zip?download=1\",\"venice.zip\"),\n",
    "    (\"https://zenodo.org/record/1186215/files/winnipeg.zip?download=1\",\"winnipeg.zip\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_dir = \"extracted_files\"\n",
    "\n",
    "for url, filename in urls:\n",
    "    # Download the file\n",
    "    download_file(url, filename)\n",
    "    \n",
    "    # Extract the contents of the ZIP file to the destination directory\n",
    "    extract_zip(filename, destination_dir)\n",
    "    \n",
    "    # Remove the downloaded ZIP file if needed\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adelaide', 'belfast', 'berlin', 'bordeaux', 'brisbane', 'canberra', 'detroit', 'dublin', 'grenoble', 'helsinki', 'kuopio', 'lisbon', 'luxembourg', 'melbourne', 'nantes', 'palermo', 'paris', 'prague', 'rennes', 'rome', 'sydney', 'toulouse', 'turku', 'venice', 'winnipeg']\n"
     ]
    }
   ],
   "source": [
    "#remove useless files. For all cities, remove ,week.gtfs.zip,week.sqlite,sections.geojson\n",
    "cities = [t[1].split(\".zip\")[0] for t in urls]\n",
    "print(cities)\n",
    "for city in cities:\n",
    "    try:\n",
    "        os.remove(\"../extracted_files/\" + city + \"/week.gtfs.zip\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try: \n",
    "        os.remove(\"../extracted_files/\" + city + \"/week.sqlite\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.remove(\"../extracted_files/\" + city + \"/sections.geojson\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adelaide', 'belfast', 'berlin', 'bordeaux', 'brisbane', 'canberra', 'detroit', 'dublin', 'grenoble', 'helsinki', 'kuopio', 'lisbon', 'luxembourg', 'melbourne', 'nantes', 'palermo', 'paris', 'prague', 'rennes', 'rome', 'sydney', 'toulouse', 'turku', 'venice', 'winnipeg']\n"
     ]
    }
   ],
   "source": [
    "#remove useless files. For all cities, remove network_temporal_weeek\n",
    "cities = [t[1].split(\".zip\")[0] for t in urls]\n",
    "print(cities)\n",
    "for city in cities:\n",
    "    try:\n",
    "        os.remove(\"../extracted_files/\" + city + \"/network_temporal_week.csv\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try: \n",
    "        os.remove(\"../extracted_files/\" + city + \"/network_temporal_day.csv\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.remove(\"../extracted_files/\" + city + \"/sections.geojson\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Iterate over each city\n",
    "cities = [t[1].split(\".zip\")[0] for t in urls]\n",
    "max_nr_transport_mode = 5 #    nr_transport_mode = combined_df['route_type'].nunique() (berlin is the highest)\n",
    "for city in cities:\n",
    "    print(f\"Processing city: {city}\")\n",
    "    \n",
    "    # Read the combined network file\n",
    "    combined_df = pd.read_csv(f\"../extracted_files/{city}/network_combined.csv\",delimiter=\";\")\n",
    "    \n",
    "    # Group by 'from_stop_I' and 'to_stop_I' columns\n",
    "    grouped = combined_df.groupby(['from_stop_I', 'to_stop_I'])\n",
    "    \n",
    "    def get_route_types(group):\n",
    "        return group['route_type'].unique().tolist()\n",
    "    \n",
    "    # Apply the get_route_types function to the grouped dataframe\n",
    "    result = grouped.apply(get_route_types).reset_index()\n",
    "    result.columns = ['from_stop_I', 'to_stop_I', 'route_type']\n",
    "    \n",
    "    def convert_route_type(route_list):\n",
    "        new_list = [0] * max_nr_transport_mode\n",
    "        for val in route_list:\n",
    "            if val >= 0 and val < max_nr_transport_mode:\n",
    "                new_list[val] = 1\n",
    "        return new_list\n",
    "    \n",
    "    # Apply the convert_route_type function to the 'route_type' column\n",
    "    result['new'] = result['route_type'].apply(convert_route_type)\n",
    "    \n",
    "    columns_to_include = ['d','n_vehicles']  # Add the names of the columns you want to include\n",
    "    for column in columns_to_include:\n",
    "        result[column] = grouped[column].mean().values\n",
    "    # Rename the 'new' column to 'value'\n",
    "    result = result.rename(columns={'new': 'label'})\n",
    "    # drop route_type\n",
    "    result = result.drop(columns=['route_type'])\n",
    "    \n",
    "    # Save the result to the edge_list.csv file in the city directory\n",
    "    os.makedirs(city, exist_ok=True)\n",
    "    result.to_csv(f\"../extracted_files/{city}/edge_list.csv\", index=False)\n",
    "    \n",
    "    print(f\"Processing for {city} completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move all edge_list for all cities in a new folder called \"processed_files\", where each file is of the form \"city_edge_list.csv\"\n",
    "for city in cities:\n",
    "    print(f\"Processing city: {city}\")\n",
    "    # Read the combined network file\n",
    "    combined_df = pd.read_csv(f\"../extracted_files/{city}/edge_list.csv\")\n",
    "    combined_df.to_csv(f\"../processed_files/{city}_edge_list.csv\", index=False)\n",
    "    print(f\"Processing for {city} completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for each city if there are not an int in from_stop_I or to_stop_I\n",
    "for city in cities:\n",
    "    print(f\"Processing city: {city}\")\n",
    "    # Read the combined network file\n",
    "    combined_df = pd.read_csv(f\"../processed_files/{city}_edge_list.csv\")\n",
    "    for i in combined_df['from_stop_I']:\n",
    "        if isinstance(i, int) == False:\n",
    "            print(f\"Error in {city} for from_stop_I\")\n",
    "    for i in combined_df['to_stop_I']:\n",
    "        if isinstance(i, int) == False:\n",
    "            print(f\"Error in {city} for to_stop_I\")\n",
    "    print(f\"Processing for {city} completed.\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
